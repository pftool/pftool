#!/usr/bin/env python3
import os.path
import sys
import subprocess
import random
import time
import argparse
import syslog
from socket import gethostname
from optparse import OptionParser
import pfscripts as pfs

def build_command(arg_parser):
    pass

def main(args):
    config = pfs.parse_config()

    jid = pfs.get_jid()
    commands = pfs.Commands()
    commands.add("-w", pfs.Work.COPY)
    commands.add("-j", jid)

    logging = False
    try:
        l = config.get("environment", "logging")
    except:
        parser.error(
            "please specify whether logging should be enabled (e.g. logging: True)")

    if l.lower() == "true":
        logging = True
        commands.add("-l")

    if args.try_attempts < 1:
        sys.exit("Try attempts must 1 or more")

    # TODO
    # This code looks not useful. Inquire later, chuck for now
    # if 1 < args.try_attempts and not args.different:
    #     sys.exit()
    #     parser.error("try attempts must be 1 if copy all files is set")

    if args.preserve:
        commands.add("-o")
    if args.verbose:
        commands.add("-v")
    if args.syn_size is not None:
        commands.add("-x")
        commands.add(args.syn_size)
    if args.syn_pattern is not None:
        commands.add("-X")
        commands.add(args.syn_pattern)
    if args.debug is not None:
        commands.add("-g")

    base_name = os.path.dirname(args.source_path[0])
    if args.recursive:
        commands.add("-r")
        for i in args.source_path:
            if os.path.dirname(i) != base_name:
                parser.error(
                    "All sources for a recursive copy must be contained within the same directory.")

    base_dest_name = os.path.dirname(args.dest_path)
    if base_dest_name and not os.path.exists(base_dest_name):
        parser.error("%s - No such file or directory" % (args.dest_path))

    # for i in src:
    #  if not os.path.exists(i):
    #    parser.error("cannot stat '%s': No such file or directory"%(i))
    try:
        writesize = config.get("options", "writesize")
        commands.add("-s", writesize)
    except:
        pass

    try:
        chunk_at = config.get("options", "chunk_at")
        chunksize = config.get("options", "chunksize")
        commands.add("-C", chunk_at)
        commands.add("-S", chunksize)
    except:
        pass

    # parse additional options
    if args.different:
        commands.add("-n")

    if args.exclude is not None:
        commands.add("-e")
        commands.add(args.exclude)

    try:
        t = config.get("environment", "parallel_dest")
        if t.lower() == "true":
            commands.add("-P")
            dest_dir = os.path.dirname(args.dest_path)
            if dest_dir == "":
                dest_dir = "."
            dest_fstype = subprocess.Popen(
                "df -TP " + dest_dir + " | grep -v Filesystem | awk -F ' ' '{print $2}'", stdout=subprocess.PIPE, shell=True).stdout.read()
            # specify the filesystem type for the destination on parallel transfers. In may make a difference! - cds 6/2014
            commands.add("-t", dest_fstype.rstrip())
    except:
        pass

#  The updates below expand relative paths to avoid hitting bugs with odd src/dst paths.  /var/lib/perceus/vnfs is likely safe to remove from *any* path...
    src_full = []
    dest_full = []
    for i in args.source_path:
        src_full.append(os.path.realpath(i))
    dest_full.append(os.path.realpath(args.dest_path))

    src_fixed = []
    dest_fixed = []
    for i in src_full:
        if i.find("/var/lib/perceus/vnfs") != "-1":
            src_fixed.append(i.split('rootfs', 1)[-1])
        else:
            src_fixed.append(i)
    for j in dest_full:
        if j.find("/var/lib/perceus/vnfs") != "-1":
            dest_fixed.append(j.split('rootfs', 1)[-1])
        else:
            dest_fixed.append(j)

    commands.add("-c", *dest_fixed)
    # src_fixed has the last '/' shaved off,
    # which is important for synthetic data sources
    if args.syn_size:
        commands.add("-p", *args.source_path)
    else:
        commands.add("-p", *src_fixed)

    threaded = False
    try:
        t = config.get("environment", "threaded")
    except:
        sys.exit("Specify threading in config (ex 'threaded: True')")

    if t.lower() == "true":
        threaded = True

    pfcmd = pfs.Commands()

    if threaded:
        # running in threaded mode on a single node
        # get the maximum # of threads
        num_procs = config.get("num_procs", "pfcp")
        # build threaded command
        pfcmd.add(pfs.PF.PFTOOL)
        pfcmd.add("-nthread", num_procs)
    else:
        # use MPI and potentially multiple nodes
        # determine which hosts to run on
        # read job control variables - if any
        host_list, procs = pfs.get_nodeallocation()
        # no job control variables - use configured values in config file
        if len(host_list) == 0:
            try:
                host_list = [x[0].lower() for x in [x for x in config.items(
                    "active_nodes") if x[1] == "ON"]]
            except:
                sys.exit(
                    "Need at least one node in config " +
                    "file set to on (e.g. localhost: ON)")

            procs = int(config.get("num_procs", "pfcp"))

        up_host = []
        for host in host_list:
            if pfs.is_ssh_running(host):
                up_host.append(host)

        host_list = up_host

        # chance are that host_list came from job control variables ...
        if "all" not in host_list:
            try:
                min_procs = int(config.get("num_procs", "min_per_node"))
            except:
                sys.exit("Specify min_per_node in config (e.g. min_per_node: 2)")

            host_cnt = len(host_list)
            test_procs = min_procs * host_cnt
            # if configured for greater minimum procs -> use that number
            if test_procs > procs:
                procs = test_procs

        num_procs = str(procs)  # make sure number pf processes is assigned

        # build mpi command
        try:
            mpigo = config.get("environment", "mpirun")
        except:
            sys.exit("specify mpirun in config file")

        pfcmd.add(mpigo)
        # should return the MPI installation root
        mpiroot = os.path.dirname(os.path.dirname(pfs.findexec(mpigo)))
        # this is a fix for "orted: command not found" issue
        pfcmd.add("-prefix", mpiroot)

        # Add darshan logging support if its available (this must be called after adding mpigo)
        pfs.add_darshan(config, pfcmd)

        # Add in the dangerous flags that are necessary for running in production
        pfcmd.add("--oversubscribe")
        pfcmd.add("--allow-run-as-root")
        pfcmd.add("--map-by", "node")
        # Export marfs config env var to all procs
        pfcmd.add("-x", "MARFSCONFIGRC")
        random.shuffle(host_list)
        if "all" not in host_list:
            pfcmd.add("-host", ",".join(host_list))
        pfcmd.add("-n", num_procs)
        pfcmd.add(pfs.PF.PFTOOL)

    # add PFTOOL arguments
    pfcmd.add(*commands.commands)

    host = gethostname()
    print("Launched %s from host %s at: %s" % (
        sys.argv[0], host, time.strftime("%a %b %d %H:%M:%S %Z %Y", time.localtime())))

    if logging:
        pfs.write_log("[pfcp] [%s] Begin Date: %s" % (
            jid, time.strftime("%a %b %d %H:%M:%S %Z %Y", time.localtime())))
        pfs.write_log("[pfcp] [%s] CMD %s" % (jid, pfcmd))

    if args.debug:
        print(pfcmd.commands)

    for i in range(0, args.try_attempts):
        status = subprocess.call(pfcmd.commands)
        # if we got nonfatal errors we can continue
        if 1 != status:
            break

    if(status != 0):
        print("ERROR: %s failed" % sys.argv[0])
        if logging:
            pfs.write_log("[pfcp] [%s] PFCP failed." % (jid), syslog.LOG_ERR)

    print("Job finished at: %s" %
          (time.strftime("%a %b %d %H:%M:%S %Z %Y", time.localtime())))
    if logging:
        pfs.write_log("[pfcp] [%s] Job End at: %s" % (
            jid, time.strftime("%a %b %d %H:%M:%S %Z %Y", time.localtime())))

    sys.exit(status)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        'pfcp',
        usage="pfcp [options] source_path dest_path",
        description="copy file(s) from source_path to dest_path in parallel"
    )

    parser.add_argument(
        'source_path',
        help='Path to source file(s)',
    )

    parser.add_argument(
        'dest_path',
        help='Path to destination',
    )

    parser.add_argument(
        '-R',
        '--recursive',
        action='store_true',
        help='Recursive action',
        default=False
    )
    parser.add_argument(
        '-v',
        '--verbose',
        action='store_true',
        help='Verbose output',
        default=False
    )

    parser.add_argument(
        '-F',
        '--different',
        action='store_true',
        help='Copy all files even if they do not appear to have changed',
        default=True
    )

    parser.add_argument(
        # development only
        '-g',
        '--debug',
        action='store_true',
        help='Allows for gdb to attach',
        default=False
    )

    parser.add_argument(
        '-p',
        '--preserve',
        action='store_true',
        help='Consider user/group ownership when comparing files to copy',
        default=False
    )

    parser.add_argument(
        '-x',
        '--syn_size',
        metavar="SIZE",
        help='development only. Option may be used for future feature',
        default=None
    )

    parser.add_argument(
        '-X',
        '--syn_pattern',
        metavar="PATTERN",
        help='development only. Option may be used for future feature',
        default=None
    )

    parser.add_argument(
        '-e',
        '--exclude',
        action='store_true',
        help='Exclude pattern',
        default=None
    )

    parser.add_argument(
        '-t',
        '--try_attempts',
        type=int,
        help='Number of times to retry on non-fatal errors',
        default=1
    )

    if len(sys.argv) < 2:
        parser.print_usage()
        sys.exit(1)

    args = parser.parse_args()
    main(args)
