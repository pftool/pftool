#!/usr/bin/env python
import os.path, sys, pwd, grp, subprocess, random
from optparse import OptionParser
from pfscripts import *

def main():
  parser = OptionParser()
  parser.usage = "%prog [options] sourcePath destinationPath"
  parser.description = "%prog -- copy file(s) from sourcePath to destinationPath in parallel"
  parser.add_option("-R", dest="recurse", default=False, action="store_true", help="copy directories recursively")
  parser.add_option("-v", dest="verbose", default=False, action="store_true", help="verbose result output")
  parser.add_option("-F", dest="different", default=True, action="store_false", help="copy all files even if they do not appear to have changed")
  parser.add_option("-g", dest="debug", default=None, action="store_true", help="development only. Allows for gdb to attach")
  parser.add_option("-p", dest="preserve", default=False, action="store_true", help="consider user/group ownership when comparing files to copy")
  parser.add_option("-x", dest="synSize", default=None, metavar="SIZE", help="development only. Option may be used for future feature")
  parser.add_option("-X", dest="synPattern", default=None, metavar="PATTERN", help="development only. Option may be used for future feature")
  parser.add_option("-e", dest="exclude", default=None, metavar="PATTERN", help="exclude pattern")
  parser.add_option("-t", dest="tryAttempts", default=1, type="int", help="Number of times to retry on non-fatal errors")
  
  (options, args) = parser.parse_args()

  config = parse_config()

  if len(args) < 2:
    parser.error("Specify the source and destination file/dir information.")

  jid = get_jid()
  src = args[:-1]
  dest = args[-1]
  commands = Commands()
  commands.add("-w", Work.COPY)
  commands.add("-j", jid)

  logging = False
  try:
    l = config.get("environment", "logging")
  except:
    parser.error("please specify whether logging should be enabled (e.g. logging: True)")

  if l.lower() == "true":
    logging = True
    commands.add("-l")

  if 0 >= options.tryAttempts:
    parser.error("try attempts must be 1 or greater for pftool to run.")

  if 1 < options.tryAttempts and not options.different:
    parser.error("try attempts must be 1 if copy all files is set")

  if options.preserve:				# consider uid/gid for file comparisons
    commands.add("-o")
  if options.verbose:				# add verbose flag to PFTOOL command line
    commands.add("-v")
  if options.synSize is not None:		# add synthetic data size to PFTOOL command line
    commands.add("-x")
    commands.add(parser.values.synSize)
  if options.synPattern is not None:		# add synthetic pattern to PFTOOL command line
    commands.add("-X")
    commands.add(parser.values.synPattern)
  if options.debug is not None:			# add debug flag to PFTOOL command line
    commands.add("-g")

  base_name = os.path.dirname(src[0])
  if options.recurse:				# add recursive flag to PFTOOL command line
    commands.add("-r")
    for i in src:
      if os.path.dirname(i) != base_name:
        parser.error("All sources for a recursive copy must be contained within the same directory.")

  base_dest_name = os.path.dirname(dest)
  if base_dest_name and not os.path.exists(base_dest_name):
   parser.error("%s - No such file or directory"%(dest)) 
  
  #for i in src:
  #  if not os.path.exists(i):
  #    parser.error("cannot stat '%s': No such file or directory"%(i))
  try:
    writesize = config.get("options", "writesize")
    commands.add("-s", writesize);
  except:
    pass

  try:
    chunk_at = config.get("options", "chunk_at")
    chunksize = config.get("options", "chunksize")
    commands.add("-C", chunk_at)
    commands.add("-S", chunksize)
  except:
    pass

  #parse additional options
  if options.different:
    commands.add("-n")
    
  if options.exclude is not None:
      commands.add("-e")
      commands.add(parser.values.exclude)


  try:
    t = config.get("environment", "parallel_dest")
    if t.lower() == "true":
        commands.add("-P")
        dest_dir = os.path.dirname(dest)
        if dest_dir == "":
          dest_dir = "."
        dest_fstype = subprocess.Popen("df -TP " + dest_dir + " | grep -v Filesystem | awk -F ' ' '{print $2}'", stdout=subprocess.PIPE, shell=True).stdout.read()
        commands.add("-t", dest_fstype.rstrip())			# specify the filesystem type for the destination on parallel transfers. In may make a difference! - cds 6/2014
  except:
    pass

#  The updates below expand relative paths to avoid hitting bugs with odd src/dst paths.  /var/lib/perceus/vnfs is likely safe to remove from *any* path...
  src_full = []
  dest_full = []
  for i in src:
      src_full.append(os.path.realpath(i))
  dest_full.append(os.path.realpath(dest))

  src_fixed = []
  dest_fixed = []
  for i in src_full:
      if i.find("/var/lib/perceus/vnfs") != "-1":
         src_fixed.append(i.split('rootfs', 1)[-1])
      else:
         src_fixed.append(i)
  for j in dest_full:
      if j.find("/var/lib/perceus/vnfs") != "-1":
         dest_fixed.append(j.split('rootfs', 1)[-1])
      else:
         dest_fixed.append(j)

  commands.add("-c", *dest_fixed)
  if options.synSize:							# src_fixed has the last '/' shaved off, which is important for synthetic data sources
     commands.add("-p", *src)
  else:
     commands.add("-p", *src_fixed)

  threaded = False
  try:
    t = config.get("environment", "threaded")
  except:
    parser.error("please specify whether the program is threaded or not in the environment section of the config file (e.g. threaded: True)")

  if t.lower() == "true":
    threaded = True


  pfcmd = Commands()

  if threaded:								# running in threaded mode on a single node
    num_procs = config.get("num_procs", "pfcp")				# get the maximum # of threads
	# build threaded command
    pfcmd.add(pftool)
    pfcmd.add("-nthread", num_procs)
  else:									# use MPI and potentially multiple nodes
	# determine which hosts to run on
    host_list,procs = get_nodeallocation()				# read job control variables - if any
    if len(host_list) == 0:						# no job control variables - use configured values in config file
      try:
        host_list = map(lambda x: x[0].lower(), filter(lambda x: x[1] == "ON", config.items("active_nodes")))
      except:
        parser.error("please specify at least 1 host in active_nodes section of the config file (e.g. localhost: ON)")
      procs = int(config.get("num_procs", "pfcp"))
    
    up_host = []
    for host in host_list:
      if is_ssh_running(host):
        up_host.append(host)

    host_list = up_host
  
    if "all" not in host_list:						# chance are that host_list came from job control variables ...
      try:
        min_procs = int(config.get("num_procs", "min_per_node"))
      except:
        parser.error("please specify a minmum number of processes to run on each mpi host (e.g. min_per_node: 2)")
      host_cnt = len(host_list)
      test_procs = min_procs * host_cnt
      if test_procs > procs:						# if configured for greater minimum procs -> use that number
        procs = test_procs

    num_procs = str(procs)						# make sure number pf processes is assigned

	# build mpi command
    try:
      mpigo = config.get("environment", "mpirun")
    except:
      parser.error("please specify the mpirun path in the environment section of the config file (e.g. mpirun: /path/to/mpirun)")

    pfcmd.add(mpigo)
    mpiroot= os.path.dirname(os.path.dirname(findexec(mpigo)))		# should return the MPI installation root
    pfcmd.add("-prefix", mpiroot)					# this is a fix for "orted: command not found" issue

    # Add darshan logging support if its available (this must be called after adding mpigo)
    add_darshan(config, pfcmd)

    # Add in the dangerous flags that are necessary for running in production
    pfcmd.add("--oversubscribe")
    pfcmd.add("--allow-run-as-root")
    pfcmd.add("--map-by","node")
    # Export marfs config env var to all procs
    pfcmd.add("-x","MARFSCONFIGRC")
    random.shuffle(host_list)
    if "all" not in host_list:
        pfcmd.add("-host", ",".join(host_list))
    pfcmd.add("-n", num_procs)
    pfcmd.add(pftool)
    
	# add PFTOOL arguments
  pfcmd.add(*commands.commands)

  host = gethostname()
  print "Launched %s from host %s at: %s"%(sys.argv[0], host, time.strftime("%a %b %d %H:%M:%S %Z %Y", time.localtime()))
  
  if logging:
    write_log("[pfcp] [%s] Begin Date: %s"%(jid, time.strftime("%a %b %d %H:%M:%S %Z %Y", time.localtime())))
    write_log("[pfcp] [%s] CMD %s"%(jid, pfcmd))


  if options.debug:
    print pfcmd.commands						# print the command out used to run PFTOOL

  for i in xrange(0, options.tryAttempts):
    status = subprocess.call(pfcmd.commands)
    # if we got nonfatal errors we can continue
    if 1 != status:
      break;

  if(status != 0):
    print "ERROR: %s failed"%sys.argv[0]
    if logging:
      write_log("[pfcp] [%s] PFCP failed."%(jid), LOG_ERR)

  
  print "Job finished at: %s"%(time.strftime("%a %b %d %H:%M:%S %Z %Y", time.localtime()))
  if logging:
    write_log("[pfcp] [%s] Job End at: %s"%(jid, time.strftime("%a %b %d %H:%M:%S %Z %Y", time.localtime())))

  sys.exit(status)


if __name__ == "__main__":
  main()
